\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{enumitem}
\title{Homework 8 -- Input/Output}
\author{Prepared by ChatGPT}
\date{\today}
\begin{document}
\maketitle
\section*{Question 1}
Programmed I/O is practical for simple peripherals that transfer small amounts of data infrequently, such as reading the state of a front-panel keypad on an embedded controller. The CPU can poll the device register as part of its control loop and immediately act on the result. Interrupt-driven I/O would add needless latency because the processor must configure interrupts and context-switch, and DMA hardware would be underutilized because the transfer granularity is tiny.

Interrupt-driven I/O shines for devices that produce data sporadically but require fast service once ready, for example a serial port receiving characters from a user terminal. The interrupt lets the processor continue other work until the device asserts service, at which point the handler quickly copies the bytes. Programmed polling would waste cycles checking the port, and DMA setup overhead would dominate for such small bursts.

Direct Memory Access (DMA) is best when a peripheral transfers large, high-throughput blocks, such as streaming disk or network adapters moving entire packets or sectors. Delegating the transfer to DMA keeps the processor free for computation. Polling would stall the CPU for the long duration of the transfer, and interrupt-driven byte handling would thrash the processor with handler overhead for each chunk.

\section*{Question 2}
Memory-mapped I/O reuses the processor's regular load/store instructions, so device registers share the physical address space with memory locations. This simplifies programming (ordinary instructions work), enables caching or burst transfers, and allows the full addressing modes of the CPU. However, it consumes portions of the memory address space and risks unwanted caching unless the region is marked as uncacheable.

Isolated (port-mapped) I/O uses a separate address space and special I/O instructions, keeping the main memory map intact and preventing accidental caching. The trade-off is extra opcodes, limited addressing modes, and often slower access because the processor must execute dedicated I/O instructions that may serialize the pipeline.

\section*{Question 3}
A character stream at 12{,}400~bps with 8~bits per character yields
\[
\text{DMA transfers} = \frac{12{,}400~\text{bits/s}}{8~\text{bits/byte}} = 1{,}550~\text{bytes/s}.
\]
With cycle stealing, each byte consumes one bus cycle, preventing the processor from fetching an instruction during that cycle. The processor issues $5\times10^{6}$ instruction fetches per second. Therefore the fractional loss of instruction fetch cycles is
\[
\frac{1{,}550}{5\times10^{6}} = 3.1\times 10^{-4} \approx 0.031\%.
\]
The processor throughput effectively drops to $5\times10^{6} - 1{,}550 \approx 4.9985\times10^{6}$ instructions per second, i.e., a slowdown of roughly $0.031\%$.

\section*{Question 4}
The processor can sustain 4~MIPS; each instruction averages four machine cycles, two of which use the memory bus. With background tasks consuming 95\% of the instruction rate, the CPU executes
\[
0.95 \times 4~\text{MIPS} = 3.8~\text{MIPS}.
\]
This requires $3.8\times 10^{6}$ instructions per second, or $15.2\times 10^{6}$ processor cycles per second. Half of those cycles (two per instruction) occupy the bus, so the background load uses $7.6\times 10^{6}$ bus cycles each second. The bus provides one transfer per cycle, so $16\times 10^{6} - 7.6\times 10^{6} = 8.4\times 10^{6}$ bus cycles remain available.

\subsection*{Programmed I/O}
Each word transfer needs four instructions. The processor has $4\times10^{6} - 3.8\times10^{6} = 0.2\times10^{6}$ instructions per second available for I/O service. Dividing by four instructions per transfer gives a maximum of
\[
\frac{0.2\times10^{6}}{4} = 5.0\times10^{4}
\]
word transfers per second. This rate consumes $5.0\times10^{4} \times 8 = 0.4\times10^{6}$ bus cycles (two bus cycles per instruction), well below the unused $8.4\times10^{6}$ cycles, so the CPU is the limiting factor. Thus the programmed I/O throughput is approximately $5.0\times10^{4}$ words/s.

\subsection*{DMA}
DMA removes the instruction overhead; only bus availability limits the transfer. Moving each word between memory and device requires two bus cycles (one to read from memory, one to write to the device). Using the $8.4\times10^{6}$ free bus cycles gives
\[
\frac{8.4\times10^{6}}{2} = 4.2\times10^{6}
\]
word transfers per second via DMA.

\section*{Question 5}
To identify the interrupting device, a processor can:
\begin{itemize}[leftmargin=*]
  \item Employ vectored interrupts where the device places a unique vector on the bus during the acknowledge cycle.
  \item Cascade priority encoders or controllers (e.g., daisy-chained interrupt request lines) so the controller signals the highest-priority requesting device.
  \item Poll all potential devices in software by querying their status registers after receiving a generic interrupt.
\end{itemize}

When a DMA controller seizes the bus, the processor either stalls (wait states) or executes instructions that do not require bus access, because it cannot perform memory operations until the DMA relinquishes control. Many architectures tri-state their bus drivers and pause memory references while DMA cycles proceed.

\end{document}
